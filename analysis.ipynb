{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit8b28e727aaea4118ae45a8e877d5f5ff",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "\n",
    "cols = ['id', 'host_id', 'host_since', 'host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', \n",
    "        'neighbourhood_cleansed', 'latitude', 'longitude', 'host_listings_count',\n",
    "        'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', \n",
    "        'beds', 'bed_type', 'amenities', 'square_feet', 'price', 'weekly_price', \n",
    "        'monthly_price', 'security_deposit', 'cleaning_fee', 'guests_included', \n",
    "        'extra_people', 'minimum_nights', 'maximum_nights', 'number_of_reviews',\n",
    "        'first_review', 'last_review', 'review_scores_rating',\n",
    "        'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "        'review_scores_checkin', 'review_scores_communication',\n",
    "        'review_scores_location', 'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "df = pd.read_csv('paris_airbnb.csv', usecols=cols)\n",
    "\n",
    "def excel_dt_to_dt(x):\n",
    "    \"\"\"Method to be applied to df column of excel dates in day format. \n",
    "    Args:\n",
    "        x - value to be processed\n",
    "\n",
    "    Returns:\n",
    "        processed value of x\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x = datetime.date(1899,12,30) + datetime.timedelta(days=int(x))\n",
    "    except ValueError:\n",
    "        x = datetime.date(1899,12,30)\n",
    "    return x\n",
    "\n",
    "df['host_since'] = df['host_since'].apply(excel_dt_to_dt)\n",
    "df['first_review'] = df['first_review'].apply(excel_dt_to_dt)\n",
    "df['last_review'] = df['last_review'].apply(excel_dt_to_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def mapping_data(df: \"Dataframe\", sh: int = 0, min_cd: tuple = (-200, -200), max_cd: tuple = (200, 200)) -> list:\n",
    "    \"\"\"Function to create lists of coordinates from a dataframe of Airbnb listing data.\n",
    "    Args:\n",
    "        df - pandas Dataframe containing latitude and longitude\n",
    "        sh (Optional) - value of 1 will turn on superhost filter\n",
    "        min_cd (Optional) - minimum coordiante vals to accept in form (x, y)\n",
    "        max_cd (Optional) - maximum coordiante vals to accept in form (x, y)\n",
    "\n",
    "    Returns:\n",
    "        x - list of longitudes\n",
    "        y - list of latitudes\n",
    "    \"\"\"\n",
    "\n",
    "    x , y = [], []\n",
    "    for i in range(len(df)):\n",
    "        if sh == 1:\n",
    "            if df['host_is_superhost'][i] == 't':\n",
    "                if max_cd[0] > df['longitude'][i] > min_cd[0] and max_cd[1] > df['latitude'][i] > min_cd[1]:\n",
    "                    x.append(df['longitude'][i])\n",
    "                    y.append(df['latitude'][i])                \n",
    "        else:\n",
    "            if max_cd[0] > df['longitude'][i] > min_cd[0] and max_cd[1] > df['latitude'][i] > min_cd[1]:\n",
    "                x.append(df['longitude'][i])\n",
    "                y.append(df['latitude'][i]) \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "x, y = mapping_data(df)\n",
    "\n",
    "ax.scatter(x, y, edgecolor='red', linewidths=0.5, zorder=2, s=0.1)\n",
    "ax.imshow(mpimg.imread('paris_map.png'), extent=(2.2164, 2.4664, 48.799, 48.917), zorder=1)\n",
    "\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "x1, y1 = mapping_data(df)\n",
    "x2, y2 = mapping_data(df, 1)\n",
    "\n",
    "ax.scatter(x1, y1, edgecolor='red', linewidths=0.5, zorder=2, s=0.1)\n",
    "ax.scatter(x2, y2, edgecolor='yellow', linewidths=0.5, zorder=2, s=0.3)\n",
    "ax.imshow(mpimg.imread('paris_map.png'), extent=(2.2164, 2.4664, 48.799, 48.917), zorder=1)\n",
    "\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the number of superhosts is most concentrated within the coordinates 48D53'N, 2D20'E and 48D51'N, 2D23'E; \n",
    "# and the lone grid square 48D54'N, 2D20'E and 48D53'N, 2D21'E\n",
    "# These need to be converted to decimal before we can plot\n",
    "import re\n",
    "\n",
    "def min_to_dec(cd: list) -> list:\n",
    "    \"\"\"Function to convert minute coords of the form xxDyy' into decimal coords.\n",
    "    Args:\n",
    "        cd - coords to be converted\n",
    "        \n",
    "    Returns:\n",
    "        cd - converted coords in decimal form\n",
    "    \"\"\"\n",
    "    dec_cds = []\n",
    "    for coord in cd:\n",
    "        split = re.findall(r'(\\d*)D(\\d\\d)\\'.*', coord)[0]\n",
    "        dec_min = int(split[1])/60\n",
    "        dec_cd = int(split[0]) + dec_min\n",
    "        dec_cds.append(dec_cd)\n",
    "\n",
    "    return dec_cds\n",
    "\n",
    "# The first four coords relate to the top left corner and bottom right corner of 6 densely packed grid squares\n",
    "# The last four coords relate to the top left and bottom right of a single densely packed square above this\n",
    "coords = ['48D53\\'N', '2D20\\'E', '48D51\\'N', '2D23\\'E', '48D54\\'N', '2D21\\'E']\n",
    "decimal_coords = min_to_dec(coords)\n",
    "\n",
    "# Our first block of data will be between 48D53'N, 48D51'N and 2D20'E, 2D23'E\n",
    "min_1 = (decimal_coords[1], decimal_coords[2])\n",
    "max_1 = (decimal_coords[3], decimal_coords[0])\n",
    "# Our second block will be between 48D54'N, 48D53'N and 2D20'E and 2D21'E\n",
    "min_2 = (decimal_coords[1], decimal_coords[0])\n",
    "max_2 = (decimal_coords[5], decimal_coords[4])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "x1, y1 = mapping_data(df, min_cd=min_1, max_cd=max_1)\n",
    "x2, y2 = mapping_data(df, 1, min_1, max_1)\n",
    "x3, y3 = mapping_data(df, min_cd=min_2, max_cd=max_2)\n",
    "x4, y4 = mapping_data(df, 1, min_2, max_2)\n",
    "\n",
    "ax.scatter(x1, y1, edgecolor='red', linewidths=0.5, zorder=2, s=0.1)\n",
    "ax.scatter(x2, y2, edgecolor='yellow', linewidths=0.5, zorder=2, s=0.3)\n",
    "ax.scatter(x3, y3, edgecolor='red', linewidths=0.5, zorder=2, s=0.1)\n",
    "ax.scatter(x4, y4, edgecolor='yellow', linewidths=0.5, zorder=2, s=0.3)\n",
    "ax.imshow(mpimg.imread('paris_map.png'), extent=(2.2164, 2.4664, 48.799, 48.917), zorder=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of listings and superhosts in dense region\n",
    "num_list_dense = len(x3)\n",
    "num_list_dense_sh = len(x4)\n",
    "ratio_dense = num_list_dense_sh/num_list_dense\n",
    "\n",
    "# Find number of listings and superhosts across all regions\n",
    "num_list_tot = len(x1)\n",
    "num_list_tot_sh = len(x2)\n",
    "ratio_tot = num_list_tot_sh/num_list_tot\n",
    "\n",
    "print(ratio_dense, ratio_tot)\n",
    "# Superhosts account for a smaller number of total listings in the more densely packed region than across the entirety of Paris -> does this indicate oversaturation?\n",
    "\n",
    "# Find number of listings and superhosts per neighbourhood\n",
    "import pprint\n",
    "def get_neighbourhood_vals(df: \"Dataframe\") -> dict:\n",
    "    \"\"\"Get the number of listings and superhosts per region.\n",
    "    Args:\n",
    "        df - pandas dataframe of AirBnB listings\n",
    "\n",
    "    Returns:\n",
    "        nbhd_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews, \n",
    "            std_nobook, superhost_nobook]}\n",
    "    \"\"\"\n",
    "    nbhd_vals = {}\n",
    "    for i in range(len(df)):\n",
    "        nbhd_vals.setdefault(df['neighbourhood_cleansed'][i], [0, 0, 0, 0, 0, 0])\n",
    "        if df['host_is_superhost'][i] == 't':\n",
    "            nbhd_vals[df['neighbourhood_cleansed'][i]][2] += 1\n",
    "            if df['number_of_reviews'][i] == 0:\n",
    "                nbhd_vals[df['neighbourhood_cleansed'][i]][5] += 1\n",
    "            else:\n",
    "                nbhd_vals[df['neighbourhood_cleansed'][i]][3] += df['number_of_reviews'][i]\n",
    "        else:\n",
    "            nbhd_vals[df['neighbourhood_cleansed'][i]][0] += 1\n",
    "            if df['number_of_reviews'][i] == 0:\n",
    "                nbhd_vals[df['neighbourhood_cleansed'][i]][4] += 1\n",
    "            else:\n",
    "                nbhd_vals[df['neighbourhood_cleansed'][i]][1] += df['number_of_reviews'][i]\n",
    "\n",
    "    return nbhd_vals\n",
    "\n",
    "# Then find average number of listings for all of the above\n",
    "nbhd_vals = get_neighbourhood_vals(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of average bookings to total listings -> identify oversaturation\n",
    "from copy import deepcopy\n",
    "def neighourhood_ratios(nbhd_vals: dict) -> dict:\n",
    "    \"\"\"Generate ratio of superhost listings to total listings and superhost bookings(review proxy) to total bookings.\n",
    "    Args:\n",
    "        nbhd_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews]}\n",
    "\n",
    "    Returns:\n",
    "        ratio_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews,\n",
    "                listing_ratio, review_ratio]}\n",
    "    \"\"\"\n",
    "    ratio_vals = deepcopy(nbhd_vals)\n",
    "    for k,v in ratio_vals.items():\n",
    "        ratio_vals[k].append(v[2]/v[0])\n",
    "        ratio_vals[k].append(v[3]/v[1])\n",
    "    return ratio_vals\n",
    "\n",
    "nbhd_vals_ratio = neighourhood_ratios(nbhd_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of inactive properties that have at least 1 review (i.e. no reviews within last 365 days)\n",
    "# Find most recent date in dataset\n",
    "\n",
    "# Find properties with at least one review but non within 365 days\n",
    "\n",
    "def find_inactive_listings(df: \"Dataframe\", nbhd_vals: dict) -> dict:\n",
    "    \"\"\"Get the number of inactive listings per region.\n",
    "    Args:\n",
    "        df - pandas dataframe of AirBnB listings\n",
    "        nbhd_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews, \n",
    "            std_nobook, superhost_nobook, listing_ratio, review_ratio]}\n",
    "\n",
    "    Returns:\n",
    "        new_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews, \n",
    "            std_nobook, superhost_nobook, listing_ratio, review_ratio, std_inactive, superhost_inactive]}\n",
    "    \"\"\"\n",
    "    inactive_threshold = df['last_review'].max() - datetime.timedelta(days=365)\n",
    "    # Extend our placeholders\n",
    "    new_vals = deepcopy(nbhd_vals)\n",
    "    for k in new_vals.keys():\n",
    "        new_vals[k].append(0)\n",
    "        new_vals[k].append(0)\n",
    "\n",
    "    # Count inactive properties\n",
    "    for i in range(len(df)):\n",
    "        if df['host_is_superhost'][i] == 't':\n",
    "            if df['last_review'][i] < inactive_threshold:\n",
    "                new_vals[df['neighbourhood_cleansed'][i]][9] += 1\n",
    "        else:\n",
    "            if df['last_review'][i] < inactive_threshold:\n",
    "                new_vals[df['neighbourhood_cleansed'][i]][8] += 1\n",
    "\n",
    "    return new_vals\n",
    "\n",
    "nbhd_vals_inact = find_inactive_listings(df, nbhd_vals_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ratio of inactive bookings\n",
    "def inactive_ratios(nbhd_vals: dict) -> dict:\n",
    "    \"\"\"Generate ratio of inactive superhost and total listings.\n",
    "    Args:\n",
    "        nbhd_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews, \n",
    "            std_nobook, superhost_nobook, listing_ratio, review_ratio, std_inactive, superhost_inactive]}\n",
    "    Returns:\n",
    "        inactive_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [std_listing, std_reviews, superhost_listing, superhost_reviews, \n",
    "            std_nobook, superhost_nobook, listing_ratio, review_ratio, std_inactive, superhost_inactive,\n",
    "            total_inact_rat, superhost_inact_rat]}\n",
    "    \"\"\"\n",
    "    inactive_vals = deepcopy(nbhd_vals)\n",
    "    for k,v in inactive_vals.items():\n",
    "        inactive_vals[k].append(v[8]/v[0])\n",
    "        inactive_vals[k].append(v[9]/v[2])\n",
    "    return inactive_vals\n",
    "\n",
    "nbhd_inact_ratio = inactive_ratios(nbhd_vals_inact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Listings                    59942.000000\nTotal Reviews                    818361.000000\nSuperhost Listings                 6091.000000\nSuperhost Reviews                289651.000000\nNo Reviews (Total)                15094.000000\nNo Reviews (Superhost)              158.000000\nListing Ratio                         2.169724\nReview Ratio                          7.075490\nTotal Inactive (365 days)         26412.000000\nSuperhost Inactive (365 days)       277.000000\nTotal Inactive Ratio                  8.594592\nSuperhost Inactive Ratio              0.925122\ndtype: float64\n"
    }
   ],
   "source": [
    "\n",
    "# Create new dataframe of neighbourhood level data\n",
    "df2 = pd.DataFrame.from_dict(nbhd_inact_ratio, orient='index',\n",
    "                            columns = ['Total Listings', 'Total Reviews', 'Superhost Listings', \n",
    "                            'Superhost Reviews', 'No Reviews (Total)', 'No Reviews (Superhost)', \n",
    "                            'Listing Ratio', 'Review Ratio', 'Total Inactive (365 days)', \n",
    "                            'Superhost Inactive (365 days)', 'Total Inactive Ratio', 'Superhost Inactive Ratio'])\n",
    "df2.head()\n",
    "print(df2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia \n",
    "from decimal import getcontext\n",
    "# wikpedia API returns decimal objects, set precision to 3\n",
    "getcontext().prec = 3\n",
    "# Popular destinations taken from: https://upload.wikimedia.org/wikipedia/commons/a/a8/Paris_printable_tourist_attractions_map.jpg\n",
    "pages = ['Arc de Triomphe', 'Eiffel Tower', 'Champ de Mars', 'Champs-Élysées',\n",
    "    'Grand Palais', 'Pont Alexandre III', 'Les Invalides', 'Place de la Concorde',\n",
    "    'Tuileries Garden', 'Musée d\\'Orsay', 'Sacré-Cœur, Paris', 'Moulin Rouge', \n",
    "    'Galeries Lafayette', 'Palais Garnier', 'Louvre', 'Pont Neuf', 'Sainte-Chapelle',\n",
    "    'Notre-Dame de Paris', 'University of Paris', 'Panthéon', 'Centre Pompidou',\n",
    "    'Hôtel de Ville, Paris', 'Place de la Bastille', 'Les Halles']\n",
    "\n",
    "def parse_page_coords(pages: list) -> dict:\n",
    "    \"\"\"Function to parse coordinates from wiki pages.\n",
    "    Args:\n",
    "        pages - list of wiki pages to parse\n",
    "\n",
    "    Returns:\n",
    "        df-friendly dict format of page coordinates [lat, long]\n",
    "    \"\"\"\n",
    "    attraction_coords = {}\n",
    "    for page in pages:\n",
    "        wiki_page = wikipedia.page(title=page)\n",
    "        attraction_coords.setdefault(page, [])\n",
    "        try:\n",
    "            coords = wiki_page.coordinates\n",
    "            coords = [float(coords[0]), float(coords[1])]\n",
    "            attraction_coords[page] = coords\n",
    "        except KeyError:\n",
    "            # If we can't find the coordinates, we aren't interested\n",
    "            attraction_coords.pop(page)\n",
    "    return attraction_coords\n",
    "\n",
    "attraction_coords = parse_page_coords(pages)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# We will then use the Google Maps API to determine the time between the (listing) and \n",
    "# each of the popular attractions. We will write this to a df friendly dict in the form\n",
    "# {listing_id: [time_to_1, time_to_2, time_to_3...]}\n",
    "\n",
    "import importlib\n",
    "import helpers\n",
    "importlib.reload(helpers)\n",
    "def get_attraction_times(origin: dict, dest: dict) -> dict:\n",
    "    \"\"\"Get time between Paris neighbourhood and attractions.\n",
    "    Args:\n",
    "        origin - df-friendly dict format of neighbourhoods\n",
    "        dest - df-friendly dict format of page coordinates [lat, long]\n",
    "\n",
    "    Returns:\n",
    "        times - df-friendly dict format of listing ids and travel times to attractions\n",
    "    \"\"\"\n",
    "    times = {}\n",
    "    for loc in neighorigin     try:\n",
    "            times.setdefault(loc, [])\n",
    "            origin_ = helpers.geocode_location(loc)\n",
    "            for j in dest.keys():\n",
    "                dest_ = (dest[j][0], dest[j][1])\n",
    "                distance = helpers.get_distance(origin_, dest_)\n",
    "                time = helpers.parse_request_data(distance)\n",
    "                times[loc].append(time)\n",
    "        except (IndexError, KeyError) as e:\n",
    "            print(loc)\n",
    "            print(e)\n",
    "    return times\n",
    "\n",
    "timeneighbourhoods = ['Montparnasse', 'Hotel-de-Ville', 'Menilmontant', 'Rue de Vaugirard', '11th arrondissement',                              'Montmartre', 'Elysee', 'Place du Panthéon', '10th arrondissement', '13th arrondissement', \n",
    "                '9th arrondissement', '6th arrondissement', '19th arrondissement', '3rd arrondissement', \n",
    "                '1st arrondissement', '7th arrondissement', '12th arrondissement', '2nd arrondissement', \n",
    "                '17th arrondissement', '16th arrondissement']s = get_attraction_times(nbhd_neighbourhoodsraction_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can generate a new dataframe of distance data and regions\n",
    "df3 = pd.DataFrame.from_dict(times, orient='index',\n",
    "                            columns=attraction_coords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3858\n9820\n56213\n"
    }
   ],
   "source": [
    "# Determine which hosts have multiple properties\n",
    "def find_multi_hosts(df: \"DataFrame\") -> list:\n",
    "    \"\"\"Determine which host IDs appear multiple times.\n",
    "    Args:\n",
    "        df - pandas dataframe of AirBnB listings\n",
    "    \n",
    "    Returns:\n",
    "        multi_hosts - list of host IDs\n",
    "    \"\"\"\n",
    "    multi_hosts = df[df.duplicated('host_id')]['host_id'].tolist()\n",
    "    # Number of unique multi_hosts\n",
    "    print(df[df.duplicated('host_id')]['host_id'].nunique())\n",
    "    return multi_hosts\n",
    "\n",
    "multi_hosts = find_multi_hosts(df)\n",
    "\n",
    "# Total number of hosts\n",
    "num_hosts = df['host_id'].nunique()\n",
    "print(num_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multi-host df\n",
    "df1 = df[df['host_listings_count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of multi-hosts\n",
    "num_mh = df1[df1.duplicated('host_id')]['host_id'].nunique()\n",
    "# Find number of hosts\n",
    "num_hosts = df['host_id'].nunique()\n",
    "# Number of listings\n",
    "num_list_mh = len(df1)\n",
    "num_list_tot = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate df of active listings\n",
    "date_range = [df['last_review'].max()-datetime.timedelta(days=x) for x in range(366)]\n",
    "df_act = df[df['last_review'].isin(date_range)]\n",
    "df1_act = df1[df1['last_review'].isin(date_range)]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average price\n",
    "avg_prc_tot = df_act['price'].sum()/len(df_act)\n",
    "avg_prc_mh = df1_act['price'].sum()/len(df1_act)\n",
    "# Find average price per room\n",
    "av_rm_tot = avg_prc_tot/df_act['accommodates'].mean()\n",
    "av_rm_mh = avg_prc_mh/df1_act['accommodates'].mean()\n",
    "# Find average bookings\n",
    "avg_book_tot = df_act['number_of_reviews'].sum()/len(df_act)\n",
    "avg_book_mh = df1_act['number_of_reviews'].sum()/len(df1_act)\n",
    "# Estimated cash flow\n",
    "avg_cf_tot = avg_prc_tot*avg_book_tot*len(df_act)\n",
    "avg_cf_mh = avg_prc_mh*avg_book_mh*len(df1_act)\n",
    "# Estimated AirBnB revenue, @3% of host and 6% guest\n",
    "avg_rev_tot = avg_cf_tot*0.03 + avg_cf_tot*0.06\n",
    "avg_rev_mh = avg_cf_mh*0.03 + avg_cf_mh*0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate df of booked and unbooked listings\n",
    "df_b = df[df['number_of_reviews'].isin(range(1, df['number_of_reviews'].max()))]\n",
    "df_ub = df[df['number_of_reviews'].isin([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate subset dfs of people with and without profile pictures & verfication\n",
    "df_b_pp = df_b[(df_b['host_has_profile_pic'] == 't') & (df_b['host_identity_verified'] == 't')]\n",
    "df_b_npp = df_b[~((df_b['host_has_profile_pic'] == 't') & (df_b['host_identity_verified'] == 't'))]\n",
    "\n",
    "df_ub_pp = df_ub[(df_ub['host_has_profile_pic'] == 't') & (df_ub['host_identity_verified'] == 't')]\n",
    "df_ub_npp = df_ub[~((df_ub['host_has_profile_pic'] == 't') & (df_ub['host_identity_verified'] == 't'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % with profile pic and verification\n",
    "ppv_b = len(df_b_pp)/len(df_b)\n",
    "ppv_ub = len(df_ub_pp)/len(df_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average price\n",
    "avg_prc_ub = df_ub['price'].sum()/len(df_ub)\n",
    "# Find average bookings\n",
    "avg_book_ub = 7\n",
    "# Estimated cash flow\n",
    "avg_cf_ub = avg_prc_ub*avg_book_ub*len(df_ub)\n",
    "# Estimated AirBnB revenue, @3% of host and 6% guest\n",
    "avg_rev_ub = avg_cf_ub*0.03 + avg_cf_ub*0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of active properties in each neighbourhood\n",
    "def get_neighbourhood_vals(df: \"Dataframe\") -> dict:\n",
    "    \"\"\"Get the number of active listings per region.\n",
    "    Args:\n",
    "        df - pandas dataframe of AirBnB listings\n",
    "\n",
    "    Returns:\n",
    "        nbhd_vals - dict of reviews and listings for superhosts and total per neighbourhood\n",
    "            in form {neighbourhood: [active_listings]}\n",
    "    \"\"\"\n",
    "    nbhd_vals = {}\n",
    "    for i in range(len(df)):\n",
    "        nbhd_vals.setdefault(df['neighbourhood_cleansed'][i], 0)\n",
    "        nbhd_vals[df['neighbourhood_cleansed'][i]] += 1\n",
    "    return nbhd_vals\n",
    "\n",
    "nbhd_act = get_neighbourhood_vals(df)"
   ]
  }
 ]
}